[
  {
    "question": "Which of the following is NOT a type of telemetry data collected in OpenTelemetry?",
    "choices": ["Logs", "Metrics", "Traces", "Alerts"],
    "correct": 3,
    "section": "Observability Fundamentals",
    "explanation": "OpenTelemetry collects logs, metrics, and traces. Alerts are generated by monitoring systems, not collected by OpenTelemetry."
  },
  {
    "question": "What is the primary purpose of OpenTelemetry?",
    "choices": [
      "To store logs in a centralized database",
      "To provide a vendor-neutral observability framework",
      "To replace Kubernetes monitoring tools",
      "To send alerts to monitoring dashboards"
    ],
    "correct": 1,
    "section": "Observability Fundamentals",
    "explanation": "OpenTelemetry is an open-source, vendor-neutral observability framework enabling standard telemetry collection."
  },
  {
    "question": "Which statement about semantic conventions in OpenTelemetry is true?",
    "choices": [
      "They provide standardized naming for telemetry data",
      "They are only applicable to traces, not logs or metrics",
      "They are optional and have no impact on observability",
      "They are automatically generated and cannot be customized"
    ],
    "correct": 0,
    "section": "Observability Fundamentals",
    "explanation": "Semantic conventions provide consistent naming and structuring of telemetry data across services."
  },
  {
    "question": "Which is an example of a well-named metric in OpenTelemetry?",
    "choices": [
      "CPUUsageTotal",
      "cpu_usage_percentage",
      "node_cpu_seconds_total",
      "app.memory"
    ],
    "correct": 2,
    "section": "Observability Fundamentals",
    "explanation": "OpenTelemetry semantic conventions recommend snake_case and including units, e.g., node_cpu_seconds_total."
  },
  {
    "question": "What is the primary benefit of structured logging?",
    "choices": [
      "It improves parsing and searching of logs",
      "It reduces the amount of storage required",
      "It replaces the need for traces",
      "It eliminates the need for metrics"
    ],
    "correct": 0,
    "section": "Observability Fundamentals",
    "explanation": "Structured logs use key-value formats, making them easier to query, filter, and analyze."
  },
  {
    "question": "What are the three main telemetry signals in OpenTelemetry?",
    "choices": [
      "Logs, Events, Metrics",
      "Logs, Metrics, Traces",
      "Logs, Alarms, Metrics",
      "Metrics, Logs, Service Discovery"
    ],
    "correct": 1,
    "section": "Observability Fundamentals",
    "explanation": "OpenTelemetry collects logs, metrics, and traces as the three primary signals."
  },
  {
    "question": "What is the primary purpose of context propagation in OpenTelemetry?",
    "choices": [
      "To send logs between distributed systems",
      "To store logs in a central database",
      "To maintain trace relationships across services",
      "To collect application performance data"
    ],
    "correct": 2,
    "section": "Observability Fundamentals",
    "explanation": "Context propagation ensures traces remain linked as requests move between microservices."
  },
  {
    "question": "Which of the following telemetry signals help monitor distributed transactions?",
    "choices": ["Logs", "Traces", "Metrics", "Events"],
    "correct": 1,
    "section": "Observability Fundamentals",
    "explanation": "Traces track execution flow across services and help monitor distributed transactions."
  },
  {
    "question": "Which log level represents critical issues requiring immediate action?",
    "choices": ["DEBUG", "INFO", "WARN", "ERROR"],
    "correct": 3,
    "section": "Observability Fundamentals",
    "explanation": "ERROR logs indicate critical issues requiring immediate attention."
  },
  {
    "question": "Which best practice should be followed when adding labels to telemetry data?",
    "choices": [
      "Avoid high-cardinality labels",
      "Use timestamps as labels",
      "Store entire log messages in labels",
      "Use random values as label names"
    ],
    "correct": 0,
    "section": "Observability Fundamentals",
    "explanation": "High-cardinality labels cause performance issues; avoid unique identifiers in labels."
  },
  {
    "question": "What is the main difference between the OpenTelemetry API and SDK?",
    "choices": [
      "The API is used for instrumenting applications, while the SDK processes and exports data",
      "The API stores telemetry data, while the SDK retrieves it",
      "The SDK provides application interfaces, while the API only handles traces",
      "The API is required for tracing, but the SDK is optional"
    ],
    "correct": 0,
    "section": "OpenTelemetry API and SDK",
    "explanation": "The API provides instrumentation interfaces; the SDK handles processing and exporting."
  },
  {
    "question": "Which component is responsible for exporting telemetry data in OpenTelemetry?",
    "choices": ["Receiver", "Processor", "Exporter", "Aggregator"],
    "correct": 2,
    "section": "OpenTelemetry API and SDK",
    "explanation": "Exporters send telemetry data to backend systems."
  },
  {
    "question": "Which OpenTelemetry signal tracks the execution flow across multiple services?",
    "choices": ["Metrics", "Logs", "Traces", "Events"],
    "correct": 2,
    "section": "OpenTelemetry API and SDK",
    "explanation": "Traces capture the execution flow across multiple services."
  },
  {
    "question": "Which of the following is NOT an official OpenTelemetry SDK language?",
    "choices": ["Go", "Java", "Ruby", "Swift"],
    "correct": 2,
    "section": "OpenTelemetry API and SDK",
    "explanation": "Official SDKs include Go, Java, Python, and JavaScript; Ruby is not official."
  },
  {
    "question": "What is the purpose of context propagation in OpenTelemetry?",
    "choices": [
      "To synchronize configuration settings across services",
      "To ensure traces maintain their relationships across distributed services",
      "To collect logs efficiently in cloud environments",
      "To aggregate metrics before sending them to a backend"
    ],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "Context propagation maintains relationships between spans across services."
  },
  {
    "question": "What is the primary role of the OpenTelemetry API?",
    "choices": [
      "To store telemetry data",
      "To define language-specific interfaces for instrumentation",
      "To aggregate telemetry data",
      "To send alerts to Prometheus"
    ],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "The API defines language-specific interfaces for adding instrumentation."
  },
  {
    "question": "Which component is responsible for processing and exporting telemetry data?",
    "choices": ["API", "SDK", "CLI", "Logs Receiver"],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "The SDK handles processing and exporting of telemetry data."
  },
  {
    "question": "What is the recommended way to sample traces in OpenTelemetry?",
    "choices": [
      "Sample all traces",
      "Use head-based or tail-based sampling",
      "Store all traces in logs",
      "Drop all traces after they are received"
    ],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "OpenTelemetry supports head-based and tail-based sampling strategies."
  },
  {
    "question": "What is an OpenTelemetry Span?",
    "choices": [
      "A distributed log entry",
      "A segment of a trace representing a single operation",
      "A dashboard metric",
      "A collector configuration"
    ],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "A span represents a single operation within a trace."
  },
  {
    "question": "Which SDK pipeline component modifies telemetry data before exporting?",
    "choices": ["Exporters", "Processors", "Receivers", "Agents"],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "Processors modify telemetry data (e.g., filtering, batching) before export."
  },
  {
    "question": "Which OpenTelemetry API function is used to start a new trace span?",
    "choices": [
      "log_event()",
      "start_as_current_span()",
      "record_metric()",
      "set_label()"
    ],
    "correct": 1,
    "section": "OpenTelemetry API and SDK",
    "explanation": "start_as_current_span() creates a new span."
  },
  {
    "question": "Which component in the OpenTelemetry SDK is responsible for controlling the sampling of traces?",
    "choices": ["Exporter", "Processor", "Sampler", "Receiver"],
    "correct": 2,
    "section": "OpenTelemetry API and SDK",
    "explanation": "The Sampler determines whether a trace should be recorded and exported."
  },
  {
    "question": "Which component of the OpenTelemetry Collector is responsible for receiving telemetry data?",
    "choices": ["Processor", "Exporter", "Receiver", "Transformer"],
    "correct": 2,
    "section": "OpenTelemetry Collector",
    "explanation": "Receivers ingest telemetry data into the Collector."
  },
  {
    "question": "Which of the following deployment models is NOT supported by the OpenTelemetry Collector?",
    "choices": [
      "Sidecar Agent",
      "Centralized Collector",
      "Kubernetes Operator",
      "Standalone Server"
    ],
    "correct": 2,
    "section": "OpenTelemetry Collector",
    "explanation": "Collector supports sidecar, centralized, and standalone models; not Kubernetes Operator."
  },
  {
    "question": "What does an OpenTelemetry Collector processor do?",
    "choices": [
      "Ingests data from various sources",
      "Applies transformations such as filtering and batching",
      "Exports telemetry data to a backend",
      "Stores telemetry data in a database"
    ],
    "correct": 1,
    "section": "OpenTelemetry Collector",
    "explanation": "Processors modify and filter telemetry data before exporting."
  },
  {
    "question": "What is the purpose of an OpenTelemetry pipeline?",
    "choices": [
      "To define how telemetry data flows from receivers to exporters",
      "To store data in a time-series database",
      "To execute machine learning models on traces",
      "To secure telemetry data using encryption"
    ],
    "correct": 0,
    "section": "OpenTelemetry Collector",
    "explanation": "Pipelines define how data is collected, processed, and exported."
  },
  {
    "question": "Which of the following is a valid OpenTelemetry Collector exporter?",
    "choices": ["Kafka", "Elasticsearch", "Jaeger", "All of the above"],
    "correct": 3,
    "section": "OpenTelemetry Collector",
    "explanation": "Collector supports multiple exporters including Kafka, Elasticsearch, and Jaeger."
  },
  {
    "question": "What is the role of the OpenTelemetry Collector?",
    "choices": [
      "To visualize logs and traces",
      "To ingest, process, and export telemetry data",
      "To store logs in a database",
      "To replace monitoring dashboards"
    ],
    "correct": 1,
    "section": "OpenTelemetry Collector",
    "explanation": "The Collector acts as a processing hub for telemetry signals."
  },
  {
    "question": "Which OpenTelemetry Collector component is responsible for modifying data?",
    "choices": ["Receiver", "Exporter", "Processor", "Sampler"],
    "correct": 2,
    "section": "OpenTelemetry Collector",
    "explanation": "Processors modify data in the pipeline."
  },
  {
    "question": "What is the purpose of a batch processor in the OpenTelemetry Collector?",
    "choices": [
      "To store telemetry data in memory",
      "To reduce the number of telemetry requests",
      "To generate alerts",
      "To format telemetry data as JSON"
    ],
    "correct": 1,
    "section": "OpenTelemetry Collector",
    "explanation": "Batch processors optimize performance by grouping telemetry before export."
  },
  {
    "question": "Which OpenTelemetry Collector component sends telemetry data to backends?",
    "choices": ["Receiver", "Processor", "Exporter", "Transformer"],
    "correct": 2,
    "section": "OpenTelemetry Collector",
    "explanation": "Exporters send telemetry data to backend observability platforms."
  },
  {
    "question": "Which method can help reduce high-cardinality issues in OpenTelemetry metrics?",
    "choices": [
      "Using more labels in every metric",
      "Removing all labels from traces",
      "Avoiding unique identifiers in label values",
      "Storing metrics in JSON format"
    ],
    "correct": 2,
    "section": "Maintaining and Debugging",
    "explanation": "Avoid unique identifiers (e.g., user IDs) in label values to reduce cardinality."
  },
  {
    "question": "What is one common cause of missing spans in distributed traces?",
    "choices": [
      "Logs not being formatted correctly",
      "Context propagation being broken between services",
      "Not enough CPU resources being allocated",
      "Using an incorrect database schema"
    ],
    "correct": 1,
    "section": "Maintaining and Debugging",
    "explanation": "Missing spans often result from incorrect trace context propagation between services."
  },
  {
    "question": "How can schema management benefit an OpenTelemetry deployment?",
    "choices": [
      "It ensures backward compatibility when renaming metrics",
      "It compresses logs for better storage efficiency",
      "It prevents OpenTelemetry from exporting traces",
      "It enables dynamic service discovery"
    ],
    "correct": 0,
    "section": "Maintaining and Debugging",
    "explanation": "Schema management prevents breaking queries when renaming metrics or attributes."
  },
  {
    "question": "Which debugging step is recommended if no telemetry data is received in OpenTelemetry Collector?",
    "choices": [
      "Restart the database service",
      "Verify the receiver configuration",
      "Disable all traces",
      "Increase the trace sampling rate"
    ],
    "correct": 1,
    "section": "Maintaining and Debugging",
    "explanation": "Missing telemetry data is often due to misconfigured receivers; verify their configuration."
  },
  {
    "question": "What is the recommended strategy for handling transient errors in OpenTelemetry pipelines?",
    "choices": [
      "Drop all failed telemetry data",
      "Implement retries with exponential backoff",
      "Use only synchronous processing",
      "Store errors in a separate database"
    ],
    "correct": 1,
    "section": "Maintaining and Debugging",
    "explanation": "Retry mechanisms with exponential backoff help handle transient failures."
  },
  {
    "question": "Which issue is a sign of high-cardinality problems in OpenTelemetry?",
    "choices": [
      "Missing logs",
      "Metrics consuming excessive memory",
      "Logs not appearing in dashboards",
      "Incorrect trace IDs"
    ],
    "correct": 1,
    "section": "Maintaining and Debugging",
    "explanation": "High-cardinality labels can lead to metrics consuming excessive memory."
  },
  {
    "question": "What is the best strategy to avoid telemetry data loss?",
    "choices": [
      "Implement retries with exponential backoff",
      "Send all telemetry data in real time",
      "Store all data in logs",
      "Drop data with missing attributes"
    ],
    "correct": 0,
    "section": "Maintaining and Debugging",
    "explanation": "Retries with exponential backoff help prevent data loss in pipelines."
  },
  {
    "question": "What is a common cause of missing spans in distributed tracing?",
    "choices": [
      "Incorrect metric names",
      "Incorrect context propagation",
      "High CPU utilization",
      "Log file corruption"
    ],
    "correct": 1,
    "section": "Maintaining and Debugging",
    "explanation": "Incorrect or broken context propagation leads to missing spans in traces."
  },
  {
    "question": "Which OpenTelemetry feature helps ensure schema consistency over time?",
    "choices": [
      "Schema Management",
      "Sampling",
      "Data Aggregation",
      "Span Naming"
    ],
    "correct": 0,
    "section": "Maintaining and Debugging",
    "explanation": "Schema management ensures metric and attribute consistency over time."
  },
  {
    "question": "What is the primary purpose of a dead letter queue in OpenTelemetry pipelines?",
    "choices": [
      "To optimize the performance of trace collection",
      "To store telemetry data that failed processing for later analysis and potential replay",
      "To compress historical telemetry data for long-term storage",
      "To encrypt sensitive information in trace spans"
    ],
    "correct": 1,
    "section": "Maintaining and Debugging",
    "explanation": "A DLQ stores failed telemetry data for analysis and potential replay once issues are resolved."
  }
]
